<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>fontai.config.prediction API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>fontai.config.prediction</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">from pathlib import Path
import logging
import typing as t
import inspect
import traceback
import string
from argparse import Namespace
import copy
from functools import reduce

from pydantic import BaseModel, PositiveInt, PositiveFloat, validator
import strictyaml as yml

from fontai.config.core import BaseConfigHandler, SimpleClassInstantiator, BasePipelineTransformConfig
import fontai.prediction.input_processing as input_processing
import fontai.prediction.custom_filters as custom_filters
import fontai.prediction.custom_mappers as custom_mappers

import fontai.prediction.models as custom_models

from tensorflow import keras
from tensorflow.keras import layers
import tensorflow.keras.callbacks as tf_callbacks
from tensorflow.random import set_seed

import fontai.prediction.callbacks as custom_callbacks
import fontai.io.records as records

logger = logging.getLogger(__name__)


class TrainingConfig(BaseModel):

  &#34;&#34;&#34;
  Training configuration wrapper for a Scoring ML stage
  
  Args:
      batch_size (int): batch size
      epochs (int): epochs
      steps_per_epoch (int): batches per epoch
      optimizer (keras.optimizers.Optimizer): optimizer
      loss (keras.losses.Loss): loss function
      filters t.List[t.Callable]: list of model input filter functions from `input_processing` module
      seed (int) Tensorflow global random seed
      metrics (t.List[str], optional): list of metrics to display
      callbacks (t.List[tf_callbacks.Callback], optional): list of callbakcs to use at training time.
  &#34;&#34;&#34;
  custom_filters: t.List[t.Callable] = []
  custom_mappers: t.List[t.Callable] = []
  batch_size: t.Optional[PositiveInt]
  epochs: PositiveInt
  steps_per_epoch: PositiveInt
  optimizer: keras.optimizers.Optimizer
  loss: keras.losses.Loss
  seed: PositiveInt = 1
  metrics: t.Optional[t.List[str]] = None
  callbacks: t.Optional[t.List[tf_callbacks.Callback]] = None

  #lr_shrink_factor: PositiveFloat

  @classmethod
  def from_yaml(cls, yaml):
    &#34;&#34;&#34;Instantiate from a yml.YAML object
    
    Args:
        yaml (yml.YAML): Input YAML object following the schema given by ConfigHandler.training_config_schema
    
    Returns:
        TrainingConfig: Initialised object
    &#34;&#34;&#34;
    schema_handler = SimpleClassInstantiator()
    callback_factory = CallbackFactory()
    args = yaml.data

    # the following objects are not primitive types and need to be instantiated from YAML definitions
    args[&#34;optimizer&#34;] = schema_handler.get_instance(yaml=yaml.get(&#34;optimizer&#34;), scope=keras.optimizers)
    args[&#34;loss&#34;] = schema_handler.get_instance(yaml=yaml.get(&#34;loss&#34;), scope=keras.losses)
    
    if  yaml.get(&#34;custom_filters&#34;).data != []:
      args[&#34;custom_filters&#34;] = [getattr(custom_filters, subYAML.get(&#34;name&#34;).text)(**subYAML.get(&#34;kwargs&#34;).data) for subYAML in yaml.get(&#34;custom_filters&#34;)]
    else:
      args[&#34;custom_filters&#34;] = []


    if  yaml.get(&#34;custom_mappers&#34;).data != []:
      args[&#34;custom_mappers&#34;] = [getattr(custom_mappers, subYAML.get(&#34;name&#34;).text)(**subYAML.get(&#34;kwargs&#34;).data) for subYAML in yaml.get(&#34;custom_mappers&#34;)]
    else:
      args[&#34;custom_mappers&#34;] = []


    if  yaml.get(&#34;callbacks&#34;) is not None:
      args[&#34;callbacks&#34;] = [CallbackFactory.create(yaml) for yaml in yaml.get(&#34;callbacks&#34;)]
    else:
      args[&#34;callbacks&#34;] = None

    return TrainingConfig(**args)

  class Config:
    arbitrary_types_allowed = True


class Config(BasePipelineTransformConfig):
  &#34;&#34;&#34;
  Wrapper class for the configuration of the ModelTrainingStage class
  
  Args:
      input_record_class (records.TfrWritable): Input schema class from the `textai.io.records` submodule
      training_config (TrainingConfig): Runtime configuration for training routine
      model (keras.Model): Model instance that&#39;s going to be trained
  
  &#34;&#34;&#34;
  training_config: TrainingConfig
  input_record_class: type
  model_path: str
  model: keras.Model
  charset: str

  # internal BaseModel configuration class
  class Config:
    arbitrary_types_allowed = True

  @validator(&#34;charset&#34;)
  def allowed_charsets(charset: str):
    &#34;&#34;&#34;Validator for charset attribute
    
    Args:
        charset (str): charset attribute
    
    Returns:
        str: validated charset
    
    Raises:
        ValueError: If charset is invalid
    &#34;&#34;&#34;
    allowed_vals = [&#34;all&#34;,&#34;uppercase&#34;,&#34;lowercase&#34;,&#34;digits&#34;]
    if charset in allowed_vals:
      return charset
    else:
      raise ValueError(f&#34;charset must be one of {allowed_vals}&#34;)

  @validator(&#34;input_record_class&#34;)
  def validate_input_record_class(input_record_class: type):
    &#34;&#34;&#34;Validate input record class
    
    Args:
        input_record_class (type)
    
    Returns:
        type: Validated record class
    
    Raises:
        TypeError: If record class not in allowed set
    &#34;&#34;&#34;
    if issubclass(input_record_class, records.TfrWritable):
      return input_record_class
    else:
      raise TypeError(f&#34;input_record_class must inherit from TfrWritable&#34;)


class ModelFactory(object):
  &#34;&#34;&#34;
  Factory class for ML models that takes YAML configuration objects
  
  &#34;&#34;&#34;

  def __init__(self):

    self.yaml_to_obj = SimpleClassInstantiator()

    self.SEQUENTIAL_MODEL_SCHEMA = yml.Map({
      &#34;class&#34;: yml.Str(),
      &#34;kwargs&#34;: yml.Map({&#34;layers&#34;: yml.Seq(self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA)})
      })

    self.MULTI_SEQUENTIAL_MODEL_SCHEMA = yml.Map({
      &#34;class&#34;: yml.Str(),
      &#34;kwargs&#34;: yml.MapPattern(
        yml.Str(), 
        self.yaml_to_obj.ANY_PRIMITIVES | self.SEQUENTIAL_MODEL_SCHEMA,
        )
      })

    self.PATH_TO_SAVED_MODEL_SCHEMA = yml.Map({&#34;path&#34;: yml.Str(), yml.Optional(&#34;custom_class&#34;): yml.Str()})

    self.schema_constructors = {
      self.PATH_TO_SAVED_MODEL_SCHEMA: (&#34;SAVED MODEL PATH&#34;, self.from_path),
      self.SEQUENTIAL_MODEL_SCHEMA: (&#34;KERAS SEQUENTIAL&#34;, self.from_keras_sequential),
      self.MULTI_SEQUENTIAL_MODEL_SCHEMA: (&#34;MULTI SEQUENTIAL&#34;, self.from_multi_sequential)
    }

    #self.MODEL_CONFIG_SCHEMA = reduce(lambda schema1, schema2: schema1 | schema2, list(self.schema_constructors.keys()))

  def from_yaml(self, yaml: yml.YAML):
    &#34;&#34;&#34;
    Instantiate a ML model from a YAML object that contains the model&#39;s specification
    
    Args:
        yaml (yml.YAML): YAML object
    
    Returns:
        keras.Model: instantiated model
    
    Raises:
        Exception: If no matching schema is found.
    
    &#34;&#34;&#34;
    for schema in self.schema_constructors:
      name, constructor = self.schema_constructors[schema]
      try:
        model_yaml = yml.load(yaml.as_yaml(), schema)
        logger.info(f&#34;Model schema matches {name}&#34;)
        model = constructor(model_yaml)
        return model
      except Exception as e:
        logger.debug(f&#34;Error when trying to instantiate model with schema {name}; \n Full trace: {traceback.format_exc()}&#34;)
        #print(f&#34;Model schema did not match {name}; {e}\n Full trace: {traceback.format_exc()}&#34;)
    raise Exception(&#34;No valid schema matched provided model YAML; look at DEBUG log level for more info.&#34;)

  def from_path(self,model_yaml: yml.YAML):
    &#34;&#34;&#34;
    Loads a saved model 
            
    Args:
        model_yaml (yml.YAML): YAML object
    
    Returns:
        keras.Model: instantiated model
    
    &#34;&#34;&#34;
    if &#34;custom_class&#34; in model_yaml:
      model_class = model_yaml.get(&#34;custom_class&#34;).text
      return getattr(custom_models, model_class).load(model_yaml.get(&#34;path&#34;).text)
    else:
      return keras.models.load_model(model_yaml.get(&#34;path&#34;).text)

  def from_keras_sequential(self, model_yaml: yml.YAML):
    &#34;&#34;&#34;
    Instantiate a ML model of Keras&#39; Sequential class
    
    Args:
        model_yaml (yml.YAML): YAML object

    Returns:

        keras.Model: an instance of class Model

    &#34;&#34;&#34;
    model_layers = model_yaml.get(&#34;kwargs&#34;).get(&#34;layers&#34;)
    layer_instances = [self.yaml_to_obj.get_instance(layer_yaml, layers) for layer_yaml in model_layers]
    return keras.Sequential(layer_instances)

  def from_multi_sequential(self, model_yaml: yml.YAML):
    &#34;&#34;&#34;
    Instantiate a ML model that uses multiple Keras Sequential models internally
    
    Args:
        model_yaml (yml.YAML): YAML object

    Returns:

        keras.Model: an instance of class Model

    &#34;&#34;&#34;
    args = model_yaml.get(&#34;kwargs&#34;)
    materialised_kwargs = copy.deepcopy(args.data)
    for arg in args:
      try:
        yml.load(args.get(arg).as_yaml(), self.SEQUENTIAL_MODEL_SCHEMA)
        materialised_kwargs[arg] = self.from_keras_sequential(args.get(arg))
      except Exception as e:
        logger.debug(f&#34;Parameter {arg} does not match Sequential model schema. Full trace: {traceback.format_exc()}&#34;)
    return getattr(custom_models, model_yaml.get(&#34;class&#34;).text)(**materialised_kwargs)


class CallbackFactory(object):

  &#34;&#34;&#34;Factory class for instantiating Tensorflow callback objects
  &#34;&#34;&#34;
  
  @classmethod
  def create(cls, yaml: yml.YAML) -&gt; tf_callbacks.Callback:
    &#34;&#34;&#34;Create callback from YAML object
    
    Args:
        yaml (yml.YAML): Input YAML object
    
    Raises:
        ValueError: When YAML does not match any known callback class
    &#34;&#34;&#34;
    yaml_to_obj = SimpleClassInstantiator()

    for module in [tf_callbacks, custom_callbacks]:
      try:
        callback = yaml_to_obj.get_instance(yaml, scope=module)
        return callback
      except AttributeError as e:
        message = f&#34;error loading callback from YAML {yaml.data} from module {module}: {e}\n Full trace: {traceback.format_exc()}&#34;
        #print(message)
        logging.debug(message)
    raise ValueError(&#34;Provided YAML did not match any known callback.&#34;)


class ConfigHandler(BaseConfigHandler):
  &#34;&#34;&#34;
  Wrapper for training configuration processing logic.

  &#34;&#34;&#34;

  def other_setup(self):
    self.model_factory = ModelFactory()

  @classmethod
  def get_config_schema(self):
    &#34;&#34;&#34;
    YAML configuration schema:

    input_record_class (optional, defaults to LabeledChar): name of record class that will be parsed from input files; it has to inherit from `fontai.io.records.TfrWritable`. At the moment only `LabeledChar` and `LabeledFont` are supported. If `LabeledChar`, loaded elements correspond to single images from unordered fonts. If `LabeledFont`, loaded elements correspond to tensors holding all characters corresponding to a single font.
    input_path: Input files&#39; folder with TF record files
    output_path: output files&#39; folder when scoring new data
    model_path: Output model path when training a model
    charset (optional, defaults to &#39;lowercase&#39;): One of &#39;uppercase&#39;, &#39;lowercase&#39;, &#39;digits&#39; or &#39;all&#39;, and determines the set to use for training or scoring.
    training: subYAML. See below
    model: subYAML. See below


    &#39;training&#39; subYAML schema:

    batch_size (optional, defaults to None): can be null
    epochs: number of epochs
    steps_per_epoch (optional, defauls to 10k): minibatches per epoch; this is needed because the total number of valid records is not known before runtime
    seed (optional, defaults to 1): random seed for TF functions
    metrics: List of TF metrics as strings
    loss: subYAML with keys `class` and `kwargs` to instantiate a Keras loss function
    optimizer (optional, defaults to Adam with default parameters): subYAML with keys `class` and `kwargs` to instantiate a Keras optimizer
    callbacks (optional, defaults to []): subYAML with keys `class` and `kwargs` to instantiate a Keras callback or a custom one defined in `fontai.prediction.callbacks`
    custom_filters (optional, defaults to []): subYAML with keys `name` and `kwargs` to instantiate a filtering function defined in `fontai.prediction.custom_filters` to apply just after records are deserialised for training
    custom_mappers (optional, defaults to []): subYAML with keys `name` and `kwargs` to instantiate a mapping function defined in `fontai.prediction.custom_mappings` to apply just after records are deserialised for training

    model subYAML schema:

    A subYAML with entries `class` and `kwargs` to instantiate a Keras model architecture; currently only `Sequential` types are tested. Each Keras layers is specified and instantiated analogously in the kwargs. The class name can also correspond to a custom class in `fontai.prediction.models`. the kwargs of the specified class can subsequently be Sequential keras models if needed.
    &#34;&#34;&#34;

    #self.DATA_PREPROCESSING_SCHEMA = yml.Seq(self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA) | yml.EmptyList()

    self.CUSTOM_FUNCTIONS = yml.Seq(yml.Map(
        {&#34;name&#34;: yml.Str(), 
        yml.Optional(&#34;kwargs&#34;, default = {}): yml.MapPattern(
          yml.Str(),
          self.yaml_to_obj.ANY_PRIMITIVES) | yml.EmptyDict()})) | yml.EmptyList()

    self.TRAINING_CONFIG_SCHEMA = yml.Map({
      yml.Optional(&#34;batch_size&#34;, default=None): yml.Int() | yml.EmptyNone(),
      &#34;epochs&#34;: yml.Int(),
      yml.Optional(&#34;seed&#34;, default = 1): yml.Int(),
      yml.Optional(
        &#34;metrics&#34;, 
        default = None): yml.Seq(yml.Str()) | yml.EmptyNone(),
      &#34;loss&#34;: self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA,
      yml.Optional(
        &#34;steps_per_epoch&#34;, 
        default = 10000): yml.Int(),
      yml.Optional(
        &#34;optimizer&#34;, 
        default = {&#34;class&#34;: &#34;Adam&#34;, &#34;kwargs&#34;: {}}): self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA,
      yml.Optional(
        &#34;callbacks&#34;, 
        default = None): yml.Seq(self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA)| yml.EmptyNone(),
      yml.Optional(
        &#34;custom_filters&#34;,
        default = []): self.CUSTOM_FUNCTIONS,
      yml.Optional(
        &#34;custom_mappers&#34;,
        default = []): self.CUSTOM_FUNCTIONS
    })

    schema = yml.Map({
      yml.Optional(&#34;input_path&#34;, default = None): self.IO_CONFIG_SCHEMA, 
      yml.Optional(&#34;output_path&#34;, default = None): self.IO_CONFIG_SCHEMA,
      yml.Optional(&#34;input_record_class&#34;,default = &#34;LabeledChar&#34;): yml.Str(),
      &#34;model_path&#34;: self.IO_CONFIG_SCHEMA,
      &#34;training&#34;: self.TRAINING_CONFIG_SCHEMA,
      &#34;model&#34;: yml.Any(),
      yml.Optional(&#34;charset&#34;, default = &#34;lowercase&#34;): yml.Str()
       })

    return schema

  def instantiate_config(self, config: yml.YAML) -&gt; Config:
    &#34;&#34;&#34;
    Processes a YAML instance to produce an Config instance.
        
    Args:
        config (yml.YAML): YAML object
    
    Returns:
        Config: Instantiated configuration for a Scoring ML stage
    
    &#34;&#34;&#34;
    input_path, output_path = config.get(&#34;input_path&#34;).text, config.get(&#34;output_path&#34;).text
    charset = config.get(&#34;charset&#34;).text

    input_record_class = getattr(records, config.get(&#34;input_record_class&#34;).text)

    model_path = config.get(&#34;model_path&#34;).text
    training_config = TrainingConfig.from_yaml(config.get(&#34;training&#34;))
    set_seed(training_config.seed)
    model = self.model_factory.from_yaml(config.get(&#34;model&#34;))

    return Config(
      input_record_class = input_record_class,
      input_path = input_path, 
      output_path = output_path,
      model_path = model_path,
      model = model,
      training_config = training_config,
      charset = charset,
      yaml = config)</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="fontai.config.prediction.CallbackFactory"><code class="flex name class">
<span>class <span class="ident">CallbackFactory</span></span>
</code></dt>
<dd>
<div class="desc"><p>Factory class for instantiating Tensorflow callback objects</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class CallbackFactory(object):

  &#34;&#34;&#34;Factory class for instantiating Tensorflow callback objects
  &#34;&#34;&#34;
  
  @classmethod
  def create(cls, yaml: yml.YAML) -&gt; tf_callbacks.Callback:
    &#34;&#34;&#34;Create callback from YAML object
    
    Args:
        yaml (yml.YAML): Input YAML object
    
    Raises:
        ValueError: When YAML does not match any known callback class
    &#34;&#34;&#34;
    yaml_to_obj = SimpleClassInstantiator()

    for module in [tf_callbacks, custom_callbacks]:
      try:
        callback = yaml_to_obj.get_instance(yaml, scope=module)
        return callback
      except AttributeError as e:
        message = f&#34;error loading callback from YAML {yaml.data} from module {module}: {e}\n Full trace: {traceback.format_exc()}&#34;
        #print(message)
        logging.debug(message)
    raise ValueError(&#34;Provided YAML did not match any known callback.&#34;)</code></pre>
</details>
<h3>Static methods</h3>
<dl>
<dt id="fontai.config.prediction.CallbackFactory.create"><code class="name flex">
<span>def <span class="ident">create</span></span>(<span>yaml: strictyaml.representation.YAML) ‑> tensorflow.python.keras.callbacks.Callback</span>
</code></dt>
<dd>
<div class="desc"><p>Create callback from YAML object</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>yaml</code></strong> :&ensp;<code>yml.YAML</code></dt>
<dd>Input YAML object</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>When YAML does not match any known callback class</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def create(cls, yaml: yml.YAML) -&gt; tf_callbacks.Callback:
  &#34;&#34;&#34;Create callback from YAML object
  
  Args:
      yaml (yml.YAML): Input YAML object
  
  Raises:
      ValueError: When YAML does not match any known callback class
  &#34;&#34;&#34;
  yaml_to_obj = SimpleClassInstantiator()

  for module in [tf_callbacks, custom_callbacks]:
    try:
      callback = yaml_to_obj.get_instance(yaml, scope=module)
      return callback
    except AttributeError as e:
      message = f&#34;error loading callback from YAML {yaml.data} from module {module}: {e}\n Full trace: {traceback.format_exc()}&#34;
      #print(message)
      logging.debug(message)
  raise ValueError(&#34;Provided YAML did not match any known callback.&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fontai.config.prediction.Config"><code class="flex name class">
<span>class <span class="ident">Config</span></span>
<span>(</span><span>**data: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper class for the configuration of the ModelTrainingStage class</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>input_record_class</code></strong> :&ensp;<code>records.TfrWritable</code></dt>
<dd>Input schema class from the <code>textai.io.records</code> submodule</dd>
<dt><strong><code>training_config</code></strong> :&ensp;<code><a title="fontai.config.prediction.TrainingConfig" href="#fontai.config.prediction.TrainingConfig">TrainingConfig</a></code></dt>
<dd>Runtime configuration for training routine</dd>
<dt><strong><code>model</code></strong> :&ensp;<code>keras.Model</code></dt>
<dd>Model instance that's going to be trained</dd>
</dl>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class Config(BasePipelineTransformConfig):
  &#34;&#34;&#34;
  Wrapper class for the configuration of the ModelTrainingStage class
  
  Args:
      input_record_class (records.TfrWritable): Input schema class from the `textai.io.records` submodule
      training_config (TrainingConfig): Runtime configuration for training routine
      model (keras.Model): Model instance that&#39;s going to be trained
  
  &#34;&#34;&#34;
  training_config: TrainingConfig
  input_record_class: type
  model_path: str
  model: keras.Model
  charset: str

  # internal BaseModel configuration class
  class Config:
    arbitrary_types_allowed = True

  @validator(&#34;charset&#34;)
  def allowed_charsets(charset: str):
    &#34;&#34;&#34;Validator for charset attribute
    
    Args:
        charset (str): charset attribute
    
    Returns:
        str: validated charset
    
    Raises:
        ValueError: If charset is invalid
    &#34;&#34;&#34;
    allowed_vals = [&#34;all&#34;,&#34;uppercase&#34;,&#34;lowercase&#34;,&#34;digits&#34;]
    if charset in allowed_vals:
      return charset
    else:
      raise ValueError(f&#34;charset must be one of {allowed_vals}&#34;)

  @validator(&#34;input_record_class&#34;)
  def validate_input_record_class(input_record_class: type):
    &#34;&#34;&#34;Validate input record class
    
    Args:
        input_record_class (type)
    
    Returns:
        type: Validated record class
    
    Raises:
        TypeError: If record class not in allowed set
    &#34;&#34;&#34;
    if issubclass(input_record_class, records.TfrWritable):
      return input_record_class
    else:
      raise TypeError(f&#34;input_record_class must inherit from TfrWritable&#34;)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fontai.config.core.BasePipelineTransformConfig" href="core.html#fontai.config.core.BasePipelineTransformConfig">BasePipelineTransformConfig</a></li>
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fontai.config.prediction.Config.Config"><code class="name">var <span class="ident">Config</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.Config.charset"><code class="name">var <span class="ident">charset</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.Config.input_record_class"><code class="name">var <span class="ident">input_record_class</span> : type</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.Config.model"><code class="name">var <span class="ident">model</span> : tensorflow.python.keras.engine.training.Model</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.Config.model_path"><code class="name">var <span class="ident">model_path</span> : str</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.Config.training_config"><code class="name">var <span class="ident">training_config</span> : <a title="fontai.config.prediction.TrainingConfig" href="#fontai.config.prediction.TrainingConfig">TrainingConfig</a></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="fontai.config.prediction.Config.allowed_charsets"><code class="name flex">
<span>def <span class="ident">allowed_charsets</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Validator for charset attribute</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>charset</code></strong> :&ensp;<code>str</code></dt>
<dd>charset attribute</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>validated charset</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>ValueError</code></dt>
<dd>If charset is invalid</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@validator(&#34;charset&#34;)
def allowed_charsets(charset: str):
  &#34;&#34;&#34;Validator for charset attribute
  
  Args:
      charset (str): charset attribute
  
  Returns:
      str: validated charset
  
  Raises:
      ValueError: If charset is invalid
  &#34;&#34;&#34;
  allowed_vals = [&#34;all&#34;,&#34;uppercase&#34;,&#34;lowercase&#34;,&#34;digits&#34;]
  if charset in allowed_vals:
    return charset
  else:
    raise ValueError(f&#34;charset must be one of {allowed_vals}&#34;)</code></pre>
</details>
</dd>
<dt id="fontai.config.prediction.Config.validate_input_record_class"><code class="name flex">
<span>def <span class="ident">validate_input_record_class</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>Validate input record class</p>
<h2 id="args">Args</h2>
<p>input_record_class (type)</p>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>type</code></dt>
<dd>Validated record class</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>TypeError</code></dt>
<dd>If record class not in allowed set</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@validator(&#34;input_record_class&#34;)
def validate_input_record_class(input_record_class: type):
  &#34;&#34;&#34;Validate input record class
  
  Args:
      input_record_class (type)
  
  Returns:
      type: Validated record class
  
  Raises:
      TypeError: If record class not in allowed set
  &#34;&#34;&#34;
  if issubclass(input_record_class, records.TfrWritable):
    return input_record_class
  else:
    raise TypeError(f&#34;input_record_class must inherit from TfrWritable&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fontai.config.prediction.ConfigHandler"><code class="flex name class">
<span>class <span class="ident">ConfigHandler</span></span>
</code></dt>
<dd>
<div class="desc"><p>Wrapper for training configuration processing logic.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ConfigHandler(BaseConfigHandler):
  &#34;&#34;&#34;
  Wrapper for training configuration processing logic.

  &#34;&#34;&#34;

  def other_setup(self):
    self.model_factory = ModelFactory()

  @classmethod
  def get_config_schema(self):
    &#34;&#34;&#34;
    YAML configuration schema:

    input_record_class (optional, defaults to LabeledChar): name of record class that will be parsed from input files; it has to inherit from `fontai.io.records.TfrWritable`. At the moment only `LabeledChar` and `LabeledFont` are supported. If `LabeledChar`, loaded elements correspond to single images from unordered fonts. If `LabeledFont`, loaded elements correspond to tensors holding all characters corresponding to a single font.
    input_path: Input files&#39; folder with TF record files
    output_path: output files&#39; folder when scoring new data
    model_path: Output model path when training a model
    charset (optional, defaults to &#39;lowercase&#39;): One of &#39;uppercase&#39;, &#39;lowercase&#39;, &#39;digits&#39; or &#39;all&#39;, and determines the set to use for training or scoring.
    training: subYAML. See below
    model: subYAML. See below


    &#39;training&#39; subYAML schema:

    batch_size (optional, defaults to None): can be null
    epochs: number of epochs
    steps_per_epoch (optional, defauls to 10k): minibatches per epoch; this is needed because the total number of valid records is not known before runtime
    seed (optional, defaults to 1): random seed for TF functions
    metrics: List of TF metrics as strings
    loss: subYAML with keys `class` and `kwargs` to instantiate a Keras loss function
    optimizer (optional, defaults to Adam with default parameters): subYAML with keys `class` and `kwargs` to instantiate a Keras optimizer
    callbacks (optional, defaults to []): subYAML with keys `class` and `kwargs` to instantiate a Keras callback or a custom one defined in `fontai.prediction.callbacks`
    custom_filters (optional, defaults to []): subYAML with keys `name` and `kwargs` to instantiate a filtering function defined in `fontai.prediction.custom_filters` to apply just after records are deserialised for training
    custom_mappers (optional, defaults to []): subYAML with keys `name` and `kwargs` to instantiate a mapping function defined in `fontai.prediction.custom_mappings` to apply just after records are deserialised for training

    model subYAML schema:

    A subYAML with entries `class` and `kwargs` to instantiate a Keras model architecture; currently only `Sequential` types are tested. Each Keras layers is specified and instantiated analogously in the kwargs. The class name can also correspond to a custom class in `fontai.prediction.models`. the kwargs of the specified class can subsequently be Sequential keras models if needed.
    &#34;&#34;&#34;

    #self.DATA_PREPROCESSING_SCHEMA = yml.Seq(self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA) | yml.EmptyList()

    self.CUSTOM_FUNCTIONS = yml.Seq(yml.Map(
        {&#34;name&#34;: yml.Str(), 
        yml.Optional(&#34;kwargs&#34;, default = {}): yml.MapPattern(
          yml.Str(),
          self.yaml_to_obj.ANY_PRIMITIVES) | yml.EmptyDict()})) | yml.EmptyList()

    self.TRAINING_CONFIG_SCHEMA = yml.Map({
      yml.Optional(&#34;batch_size&#34;, default=None): yml.Int() | yml.EmptyNone(),
      &#34;epochs&#34;: yml.Int(),
      yml.Optional(&#34;seed&#34;, default = 1): yml.Int(),
      yml.Optional(
        &#34;metrics&#34;, 
        default = None): yml.Seq(yml.Str()) | yml.EmptyNone(),
      &#34;loss&#34;: self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA,
      yml.Optional(
        &#34;steps_per_epoch&#34;, 
        default = 10000): yml.Int(),
      yml.Optional(
        &#34;optimizer&#34;, 
        default = {&#34;class&#34;: &#34;Adam&#34;, &#34;kwargs&#34;: {}}): self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA,
      yml.Optional(
        &#34;callbacks&#34;, 
        default = None): yml.Seq(self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA)| yml.EmptyNone(),
      yml.Optional(
        &#34;custom_filters&#34;,
        default = []): self.CUSTOM_FUNCTIONS,
      yml.Optional(
        &#34;custom_mappers&#34;,
        default = []): self.CUSTOM_FUNCTIONS
    })

    schema = yml.Map({
      yml.Optional(&#34;input_path&#34;, default = None): self.IO_CONFIG_SCHEMA, 
      yml.Optional(&#34;output_path&#34;, default = None): self.IO_CONFIG_SCHEMA,
      yml.Optional(&#34;input_record_class&#34;,default = &#34;LabeledChar&#34;): yml.Str(),
      &#34;model_path&#34;: self.IO_CONFIG_SCHEMA,
      &#34;training&#34;: self.TRAINING_CONFIG_SCHEMA,
      &#34;model&#34;: yml.Any(),
      yml.Optional(&#34;charset&#34;, default = &#34;lowercase&#34;): yml.Str()
       })

    return schema

  def instantiate_config(self, config: yml.YAML) -&gt; Config:
    &#34;&#34;&#34;
    Processes a YAML instance to produce an Config instance.
        
    Args:
        config (yml.YAML): YAML object
    
    Returns:
        Config: Instantiated configuration for a Scoring ML stage
    
    &#34;&#34;&#34;
    input_path, output_path = config.get(&#34;input_path&#34;).text, config.get(&#34;output_path&#34;).text
    charset = config.get(&#34;charset&#34;).text

    input_record_class = getattr(records, config.get(&#34;input_record_class&#34;).text)

    model_path = config.get(&#34;model_path&#34;).text
    training_config = TrainingConfig.from_yaml(config.get(&#34;training&#34;))
    set_seed(training_config.seed)
    model = self.model_factory.from_yaml(config.get(&#34;model&#34;))

    return Config(
      input_record_class = input_record_class,
      input_path = input_path, 
      output_path = output_path,
      model_path = model_path,
      model = model,
      training_config = training_config,
      charset = charset,
      yaml = config)</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="fontai.config.core.BaseConfigHandler" href="core.html#fontai.config.core.BaseConfigHandler">BaseConfigHandler</a></li>
<li>abc.ABC</li>
</ul>
<h3>Static methods</h3>
<dl>
<dt id="fontai.config.prediction.ConfigHandler.get_config_schema"><code class="name flex">
<span>def <span class="ident">get_config_schema</span></span>(<span>)</span>
</code></dt>
<dd>
<div class="desc"><p>YAML configuration schema:</p>
<p>input_record_class (optional, defaults to LabeledChar): name of record class that will be parsed from input files; it has to inherit from <code><a title="fontai.io.records.TfrWritable" href="../io/records.html#fontai.io.records.TfrWritable">TfrWritable</a></code>. At the moment only <code>LabeledChar</code> and <code>LabeledFont</code> are supported. If <code>LabeledChar</code>, loaded elements correspond to single images from unordered fonts. If <code>LabeledFont</code>, loaded elements correspond to tensors holding all characters corresponding to a single font.
input_path: Input files' folder with TF record files
output_path: output files' folder when scoring new data
model_path: Output model path when training a model
charset (optional, defaults to 'lowercase'): One of 'uppercase', 'lowercase', 'digits' or 'all', and determines the set to use for training or scoring.
training: subYAML. See below
model: subYAML. See below</p>
<p>'training' subYAML schema:</p>
<p>batch_size (optional, defaults to None): can be null
epochs: number of epochs
steps_per_epoch (optional, defauls to 10k): minibatches per epoch; this is needed because the total number of valid records is not known before runtime
seed (optional, defaults to 1): random seed for TF functions
metrics: List of TF metrics as strings
loss: subYAML with keys <code>class</code> and <code>kwargs</code> to instantiate a Keras loss function
optimizer (optional, defaults to Adam with default parameters): subYAML with keys <code>class</code> and <code>kwargs</code> to instantiate a Keras optimizer
callbacks (optional, defaults to []): subYAML with keys <code>class</code> and <code>kwargs</code> to instantiate a Keras callback or a custom one defined in <code><a title="fontai.prediction.callbacks" href="../prediction/callbacks.html">fontai.prediction.callbacks</a></code>
custom_filters (optional, defaults to []): subYAML with keys <code>name</code> and <code>kwargs</code> to instantiate a filtering function defined in <code><a title="fontai.prediction.custom_filters" href="../prediction/custom_filters.html">fontai.prediction.custom_filters</a></code> to apply just after records are deserialised for training
custom_mappers (optional, defaults to []): subYAML with keys <code>name</code> and <code>kwargs</code> to instantiate a mapping function defined in <code>fontai.prediction.custom_mappings</code> to apply just after records are deserialised for training</p>
<p>model subYAML schema:</p>
<p>A subYAML with entries <code>class</code> and <code>kwargs</code> to instantiate a Keras model architecture; currently only <code>Sequential</code> types are tested. Each Keras layers is specified and instantiated analogously in the kwargs. The class name can also correspond to a custom class in <code><a title="fontai.prediction.models" href="../prediction/models.html">fontai.prediction.models</a></code>. the kwargs of the specified class can subsequently be Sequential keras models if needed.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def get_config_schema(self):
  &#34;&#34;&#34;
  YAML configuration schema:

  input_record_class (optional, defaults to LabeledChar): name of record class that will be parsed from input files; it has to inherit from `fontai.io.records.TfrWritable`. At the moment only `LabeledChar` and `LabeledFont` are supported. If `LabeledChar`, loaded elements correspond to single images from unordered fonts. If `LabeledFont`, loaded elements correspond to tensors holding all characters corresponding to a single font.
  input_path: Input files&#39; folder with TF record files
  output_path: output files&#39; folder when scoring new data
  model_path: Output model path when training a model
  charset (optional, defaults to &#39;lowercase&#39;): One of &#39;uppercase&#39;, &#39;lowercase&#39;, &#39;digits&#39; or &#39;all&#39;, and determines the set to use for training or scoring.
  training: subYAML. See below
  model: subYAML. See below


  &#39;training&#39; subYAML schema:

  batch_size (optional, defaults to None): can be null
  epochs: number of epochs
  steps_per_epoch (optional, defauls to 10k): minibatches per epoch; this is needed because the total number of valid records is not known before runtime
  seed (optional, defaults to 1): random seed for TF functions
  metrics: List of TF metrics as strings
  loss: subYAML with keys `class` and `kwargs` to instantiate a Keras loss function
  optimizer (optional, defaults to Adam with default parameters): subYAML with keys `class` and `kwargs` to instantiate a Keras optimizer
  callbacks (optional, defaults to []): subYAML with keys `class` and `kwargs` to instantiate a Keras callback or a custom one defined in `fontai.prediction.callbacks`
  custom_filters (optional, defaults to []): subYAML with keys `name` and `kwargs` to instantiate a filtering function defined in `fontai.prediction.custom_filters` to apply just after records are deserialised for training
  custom_mappers (optional, defaults to []): subYAML with keys `name` and `kwargs` to instantiate a mapping function defined in `fontai.prediction.custom_mappings` to apply just after records are deserialised for training

  model subYAML schema:

  A subYAML with entries `class` and `kwargs` to instantiate a Keras model architecture; currently only `Sequential` types are tested. Each Keras layers is specified and instantiated analogously in the kwargs. The class name can also correspond to a custom class in `fontai.prediction.models`. the kwargs of the specified class can subsequently be Sequential keras models if needed.
  &#34;&#34;&#34;

  #self.DATA_PREPROCESSING_SCHEMA = yml.Seq(self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA) | yml.EmptyList()

  self.CUSTOM_FUNCTIONS = yml.Seq(yml.Map(
      {&#34;name&#34;: yml.Str(), 
      yml.Optional(&#34;kwargs&#34;, default = {}): yml.MapPattern(
        yml.Str(),
        self.yaml_to_obj.ANY_PRIMITIVES) | yml.EmptyDict()})) | yml.EmptyList()

  self.TRAINING_CONFIG_SCHEMA = yml.Map({
    yml.Optional(&#34;batch_size&#34;, default=None): yml.Int() | yml.EmptyNone(),
    &#34;epochs&#34;: yml.Int(),
    yml.Optional(&#34;seed&#34;, default = 1): yml.Int(),
    yml.Optional(
      &#34;metrics&#34;, 
      default = None): yml.Seq(yml.Str()) | yml.EmptyNone(),
    &#34;loss&#34;: self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA,
    yml.Optional(
      &#34;steps_per_epoch&#34;, 
      default = 10000): yml.Int(),
    yml.Optional(
      &#34;optimizer&#34;, 
      default = {&#34;class&#34;: &#34;Adam&#34;, &#34;kwargs&#34;: {}}): self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA,
    yml.Optional(
      &#34;callbacks&#34;, 
      default = None): yml.Seq(self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA)| yml.EmptyNone(),
    yml.Optional(
      &#34;custom_filters&#34;,
      default = []): self.CUSTOM_FUNCTIONS,
    yml.Optional(
      &#34;custom_mappers&#34;,
      default = []): self.CUSTOM_FUNCTIONS
  })

  schema = yml.Map({
    yml.Optional(&#34;input_path&#34;, default = None): self.IO_CONFIG_SCHEMA, 
    yml.Optional(&#34;output_path&#34;, default = None): self.IO_CONFIG_SCHEMA,
    yml.Optional(&#34;input_record_class&#34;,default = &#34;LabeledChar&#34;): yml.Str(),
    &#34;model_path&#34;: self.IO_CONFIG_SCHEMA,
    &#34;training&#34;: self.TRAINING_CONFIG_SCHEMA,
    &#34;model&#34;: yml.Any(),
    yml.Optional(&#34;charset&#34;, default = &#34;lowercase&#34;): yml.Str()
     })

  return schema</code></pre>
</details>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="fontai.config.prediction.ConfigHandler.instantiate_config"><code class="name flex">
<span>def <span class="ident">instantiate_config</span></span>(<span>self, config: strictyaml.representation.YAML) ‑> <a title="fontai.config.prediction.Config" href="#fontai.config.prediction.Config">Config</a></span>
</code></dt>
<dd>
<div class="desc"><p>Processes a YAML instance to produce an Config instance.</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>config</code></strong> :&ensp;<code>yml.YAML</code></dt>
<dd>YAML object</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="fontai.config.prediction.Config" href="#fontai.config.prediction.Config">Config</a></code></dt>
<dd>Instantiated configuration for a Scoring ML stage</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def instantiate_config(self, config: yml.YAML) -&gt; Config:
  &#34;&#34;&#34;
  Processes a YAML instance to produce an Config instance.
      
  Args:
      config (yml.YAML): YAML object
  
  Returns:
      Config: Instantiated configuration for a Scoring ML stage
  
  &#34;&#34;&#34;
  input_path, output_path = config.get(&#34;input_path&#34;).text, config.get(&#34;output_path&#34;).text
  charset = config.get(&#34;charset&#34;).text

  input_record_class = getattr(records, config.get(&#34;input_record_class&#34;).text)

  model_path = config.get(&#34;model_path&#34;).text
  training_config = TrainingConfig.from_yaml(config.get(&#34;training&#34;))
  set_seed(training_config.seed)
  model = self.model_factory.from_yaml(config.get(&#34;model&#34;))

  return Config(
    input_record_class = input_record_class,
    input_path = input_path, 
    output_path = output_path,
    model_path = model_path,
    model = model,
    training_config = training_config,
    charset = charset,
    yaml = config)</code></pre>
</details>
</dd>
<dt id="fontai.config.prediction.ConfigHandler.other_setup"><code class="name flex">
<span>def <span class="ident">other_setup</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def other_setup(self):
  self.model_factory = ModelFactory()</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="fontai.config.core.BaseConfigHandler" href="core.html#fontai.config.core.BaseConfigHandler">BaseConfigHandler</a></b></code>:
<ul class="hlist">
<li><code><a title="fontai.config.core.BaseConfigHandler.from_file" href="core.html#fontai.config.core.BaseConfigHandler.from_file">from_file</a></code></li>
<li><code><a title="fontai.config.core.BaseConfigHandler.from_string" href="core.html#fontai.config.core.BaseConfigHandler.from_string">from_string</a></code></li>
</ul>
</li>
</ul>
</dd>
<dt id="fontai.config.prediction.ModelFactory"><code class="flex name class">
<span>class <span class="ident">ModelFactory</span></span>
</code></dt>
<dd>
<div class="desc"><p>Factory class for ML models that takes YAML configuration objects</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class ModelFactory(object):
  &#34;&#34;&#34;
  Factory class for ML models that takes YAML configuration objects
  
  &#34;&#34;&#34;

  def __init__(self):

    self.yaml_to_obj = SimpleClassInstantiator()

    self.SEQUENTIAL_MODEL_SCHEMA = yml.Map({
      &#34;class&#34;: yml.Str(),
      &#34;kwargs&#34;: yml.Map({&#34;layers&#34;: yml.Seq(self.yaml_to_obj.PY_CLASS_INSTANCE_FROM_YAML_SCHEMA)})
      })

    self.MULTI_SEQUENTIAL_MODEL_SCHEMA = yml.Map({
      &#34;class&#34;: yml.Str(),
      &#34;kwargs&#34;: yml.MapPattern(
        yml.Str(), 
        self.yaml_to_obj.ANY_PRIMITIVES | self.SEQUENTIAL_MODEL_SCHEMA,
        )
      })

    self.PATH_TO_SAVED_MODEL_SCHEMA = yml.Map({&#34;path&#34;: yml.Str(), yml.Optional(&#34;custom_class&#34;): yml.Str()})

    self.schema_constructors = {
      self.PATH_TO_SAVED_MODEL_SCHEMA: (&#34;SAVED MODEL PATH&#34;, self.from_path),
      self.SEQUENTIAL_MODEL_SCHEMA: (&#34;KERAS SEQUENTIAL&#34;, self.from_keras_sequential),
      self.MULTI_SEQUENTIAL_MODEL_SCHEMA: (&#34;MULTI SEQUENTIAL&#34;, self.from_multi_sequential)
    }

    #self.MODEL_CONFIG_SCHEMA = reduce(lambda schema1, schema2: schema1 | schema2, list(self.schema_constructors.keys()))

  def from_yaml(self, yaml: yml.YAML):
    &#34;&#34;&#34;
    Instantiate a ML model from a YAML object that contains the model&#39;s specification
    
    Args:
        yaml (yml.YAML): YAML object
    
    Returns:
        keras.Model: instantiated model
    
    Raises:
        Exception: If no matching schema is found.
    
    &#34;&#34;&#34;
    for schema in self.schema_constructors:
      name, constructor = self.schema_constructors[schema]
      try:
        model_yaml = yml.load(yaml.as_yaml(), schema)
        logger.info(f&#34;Model schema matches {name}&#34;)
        model = constructor(model_yaml)
        return model
      except Exception as e:
        logger.debug(f&#34;Error when trying to instantiate model with schema {name}; \n Full trace: {traceback.format_exc()}&#34;)
        #print(f&#34;Model schema did not match {name}; {e}\n Full trace: {traceback.format_exc()}&#34;)
    raise Exception(&#34;No valid schema matched provided model YAML; look at DEBUG log level for more info.&#34;)

  def from_path(self,model_yaml: yml.YAML):
    &#34;&#34;&#34;
    Loads a saved model 
            
    Args:
        model_yaml (yml.YAML): YAML object
    
    Returns:
        keras.Model: instantiated model
    
    &#34;&#34;&#34;
    if &#34;custom_class&#34; in model_yaml:
      model_class = model_yaml.get(&#34;custom_class&#34;).text
      return getattr(custom_models, model_class).load(model_yaml.get(&#34;path&#34;).text)
    else:
      return keras.models.load_model(model_yaml.get(&#34;path&#34;).text)

  def from_keras_sequential(self, model_yaml: yml.YAML):
    &#34;&#34;&#34;
    Instantiate a ML model of Keras&#39; Sequential class
    
    Args:
        model_yaml (yml.YAML): YAML object

    Returns:

        keras.Model: an instance of class Model

    &#34;&#34;&#34;
    model_layers = model_yaml.get(&#34;kwargs&#34;).get(&#34;layers&#34;)
    layer_instances = [self.yaml_to_obj.get_instance(layer_yaml, layers) for layer_yaml in model_layers]
    return keras.Sequential(layer_instances)

  def from_multi_sequential(self, model_yaml: yml.YAML):
    &#34;&#34;&#34;
    Instantiate a ML model that uses multiple Keras Sequential models internally
    
    Args:
        model_yaml (yml.YAML): YAML object

    Returns:

        keras.Model: an instance of class Model

    &#34;&#34;&#34;
    args = model_yaml.get(&#34;kwargs&#34;)
    materialised_kwargs = copy.deepcopy(args.data)
    for arg in args:
      try:
        yml.load(args.get(arg).as_yaml(), self.SEQUENTIAL_MODEL_SCHEMA)
        materialised_kwargs[arg] = self.from_keras_sequential(args.get(arg))
      except Exception as e:
        logger.debug(f&#34;Parameter {arg} does not match Sequential model schema. Full trace: {traceback.format_exc()}&#34;)
    return getattr(custom_models, model_yaml.get(&#34;class&#34;).text)(**materialised_kwargs)</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="fontai.config.prediction.ModelFactory.from_keras_sequential"><code class="name flex">
<span>def <span class="ident">from_keras_sequential</span></span>(<span>self, model_yaml: strictyaml.representation.YAML)</span>
</code></dt>
<dd>
<div class="desc"><p>Instantiate a ML model of Keras' Sequential class</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_yaml</code></strong> :&ensp;<code>yml.YAML</code></dt>
<dd>YAML object</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>keras.Model</code></dt>
<dd>an instance of class Model</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_keras_sequential(self, model_yaml: yml.YAML):
  &#34;&#34;&#34;
  Instantiate a ML model of Keras&#39; Sequential class
  
  Args:
      model_yaml (yml.YAML): YAML object

  Returns:

      keras.Model: an instance of class Model

  &#34;&#34;&#34;
  model_layers = model_yaml.get(&#34;kwargs&#34;).get(&#34;layers&#34;)
  layer_instances = [self.yaml_to_obj.get_instance(layer_yaml, layers) for layer_yaml in model_layers]
  return keras.Sequential(layer_instances)</code></pre>
</details>
</dd>
<dt id="fontai.config.prediction.ModelFactory.from_multi_sequential"><code class="name flex">
<span>def <span class="ident">from_multi_sequential</span></span>(<span>self, model_yaml: strictyaml.representation.YAML)</span>
</code></dt>
<dd>
<div class="desc"><p>Instantiate a ML model that uses multiple Keras Sequential models internally</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_yaml</code></strong> :&ensp;<code>yml.YAML</code></dt>
<dd>YAML object</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>keras.Model</code></dt>
<dd>an instance of class Model</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_multi_sequential(self, model_yaml: yml.YAML):
  &#34;&#34;&#34;
  Instantiate a ML model that uses multiple Keras Sequential models internally
  
  Args:
      model_yaml (yml.YAML): YAML object

  Returns:

      keras.Model: an instance of class Model

  &#34;&#34;&#34;
  args = model_yaml.get(&#34;kwargs&#34;)
  materialised_kwargs = copy.deepcopy(args.data)
  for arg in args:
    try:
      yml.load(args.get(arg).as_yaml(), self.SEQUENTIAL_MODEL_SCHEMA)
      materialised_kwargs[arg] = self.from_keras_sequential(args.get(arg))
    except Exception as e:
      logger.debug(f&#34;Parameter {arg} does not match Sequential model schema. Full trace: {traceback.format_exc()}&#34;)
  return getattr(custom_models, model_yaml.get(&#34;class&#34;).text)(**materialised_kwargs)</code></pre>
</details>
</dd>
<dt id="fontai.config.prediction.ModelFactory.from_path"><code class="name flex">
<span>def <span class="ident">from_path</span></span>(<span>self, model_yaml: strictyaml.representation.YAML)</span>
</code></dt>
<dd>
<div class="desc"><p>Loads a saved model </p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>model_yaml</code></strong> :&ensp;<code>yml.YAML</code></dt>
<dd>YAML object</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>keras.Model</code></dt>
<dd>instantiated model</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_path(self,model_yaml: yml.YAML):
  &#34;&#34;&#34;
  Loads a saved model 
          
  Args:
      model_yaml (yml.YAML): YAML object
  
  Returns:
      keras.Model: instantiated model
  
  &#34;&#34;&#34;
  if &#34;custom_class&#34; in model_yaml:
    model_class = model_yaml.get(&#34;custom_class&#34;).text
    return getattr(custom_models, model_class).load(model_yaml.get(&#34;path&#34;).text)
  else:
    return keras.models.load_model(model_yaml.get(&#34;path&#34;).text)</code></pre>
</details>
</dd>
<dt id="fontai.config.prediction.ModelFactory.from_yaml"><code class="name flex">
<span>def <span class="ident">from_yaml</span></span>(<span>self, yaml: strictyaml.representation.YAML)</span>
</code></dt>
<dd>
<div class="desc"><p>Instantiate a ML model from a YAML object that contains the model's specification</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>yaml</code></strong> :&ensp;<code>yml.YAML</code></dt>
<dd>YAML object</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>keras.Model</code></dt>
<dd>instantiated model</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>If no matching schema is found.</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def from_yaml(self, yaml: yml.YAML):
  &#34;&#34;&#34;
  Instantiate a ML model from a YAML object that contains the model&#39;s specification
  
  Args:
      yaml (yml.YAML): YAML object
  
  Returns:
      keras.Model: instantiated model
  
  Raises:
      Exception: If no matching schema is found.
  
  &#34;&#34;&#34;
  for schema in self.schema_constructors:
    name, constructor = self.schema_constructors[schema]
    try:
      model_yaml = yml.load(yaml.as_yaml(), schema)
      logger.info(f&#34;Model schema matches {name}&#34;)
      model = constructor(model_yaml)
      return model
    except Exception as e:
      logger.debug(f&#34;Error when trying to instantiate model with schema {name}; \n Full trace: {traceback.format_exc()}&#34;)
      #print(f&#34;Model schema did not match {name}; {e}\n Full trace: {traceback.format_exc()}&#34;)
  raise Exception(&#34;No valid schema matched provided model YAML; look at DEBUG log level for more info.&#34;)</code></pre>
</details>
</dd>
</dl>
</dd>
<dt id="fontai.config.prediction.TrainingConfig"><code class="flex name class">
<span>class <span class="ident">TrainingConfig</span></span>
<span>(</span><span>**data: Any)</span>
</code></dt>
<dd>
<div class="desc"><p>Training configuration wrapper for a Scoring ML stage</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>batch_size</code></strong> :&ensp;<code>int</code></dt>
<dd>batch size</dd>
<dt><strong><code>epochs</code></strong> :&ensp;<code>int</code></dt>
<dd>epochs</dd>
<dt><strong><code>steps_per_epoch</code></strong> :&ensp;<code>int</code></dt>
<dd>batches per epoch</dd>
<dt><strong><code>optimizer</code></strong> :&ensp;<code>keras.optimizers.Optimizer</code></dt>
<dd>optimizer</dd>
<dt><strong><code>loss</code></strong> :&ensp;<code>keras.losses.Loss</code></dt>
<dd>loss function</dd>
<dt>filters t.List[t.Callable]: list of model input filter functions from <code>input_processing</code> module</dt>
<dt>seed (int) Tensorflow global random seed</dt>
<dt><strong><code>metrics</code></strong> :&ensp;<code>t.List[str]</code>, optional</dt>
<dd>list of metrics to display</dd>
<dt><strong><code>callbacks</code></strong> :&ensp;<code>t.List[tf_callbacks.Callback]</code>, optional</dt>
<dd>list of callbakcs to use at training time.</dd>
</dl>
<p>Create a new model by parsing and validating input data from keyword arguments.</p>
<p>Raises ValidationError if the input data cannot be parsed to form a valid model.</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TrainingConfig(BaseModel):

  &#34;&#34;&#34;
  Training configuration wrapper for a Scoring ML stage
  
  Args:
      batch_size (int): batch size
      epochs (int): epochs
      steps_per_epoch (int): batches per epoch
      optimizer (keras.optimizers.Optimizer): optimizer
      loss (keras.losses.Loss): loss function
      filters t.List[t.Callable]: list of model input filter functions from `input_processing` module
      seed (int) Tensorflow global random seed
      metrics (t.List[str], optional): list of metrics to display
      callbacks (t.List[tf_callbacks.Callback], optional): list of callbakcs to use at training time.
  &#34;&#34;&#34;
  custom_filters: t.List[t.Callable] = []
  custom_mappers: t.List[t.Callable] = []
  batch_size: t.Optional[PositiveInt]
  epochs: PositiveInt
  steps_per_epoch: PositiveInt
  optimizer: keras.optimizers.Optimizer
  loss: keras.losses.Loss
  seed: PositiveInt = 1
  metrics: t.Optional[t.List[str]] = None
  callbacks: t.Optional[t.List[tf_callbacks.Callback]] = None

  #lr_shrink_factor: PositiveFloat

  @classmethod
  def from_yaml(cls, yaml):
    &#34;&#34;&#34;Instantiate from a yml.YAML object
    
    Args:
        yaml (yml.YAML): Input YAML object following the schema given by ConfigHandler.training_config_schema
    
    Returns:
        TrainingConfig: Initialised object
    &#34;&#34;&#34;
    schema_handler = SimpleClassInstantiator()
    callback_factory = CallbackFactory()
    args = yaml.data

    # the following objects are not primitive types and need to be instantiated from YAML definitions
    args[&#34;optimizer&#34;] = schema_handler.get_instance(yaml=yaml.get(&#34;optimizer&#34;), scope=keras.optimizers)
    args[&#34;loss&#34;] = schema_handler.get_instance(yaml=yaml.get(&#34;loss&#34;), scope=keras.losses)
    
    if  yaml.get(&#34;custom_filters&#34;).data != []:
      args[&#34;custom_filters&#34;] = [getattr(custom_filters, subYAML.get(&#34;name&#34;).text)(**subYAML.get(&#34;kwargs&#34;).data) for subYAML in yaml.get(&#34;custom_filters&#34;)]
    else:
      args[&#34;custom_filters&#34;] = []


    if  yaml.get(&#34;custom_mappers&#34;).data != []:
      args[&#34;custom_mappers&#34;] = [getattr(custom_mappers, subYAML.get(&#34;name&#34;).text)(**subYAML.get(&#34;kwargs&#34;).data) for subYAML in yaml.get(&#34;custom_mappers&#34;)]
    else:
      args[&#34;custom_mappers&#34;] = []


    if  yaml.get(&#34;callbacks&#34;) is not None:
      args[&#34;callbacks&#34;] = [CallbackFactory.create(yaml) for yaml in yaml.get(&#34;callbacks&#34;)]
    else:
      args[&#34;callbacks&#34;] = None

    return TrainingConfig(**args)

  class Config:
    arbitrary_types_allowed = True</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li>pydantic.main.BaseModel</li>
<li>pydantic.utils.Representation</li>
</ul>
<h3>Class variables</h3>
<dl>
<dt id="fontai.config.prediction.TrainingConfig.Config"><code class="name">var <span class="ident">Config</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.batch_size"><code class="name">var <span class="ident">batch_size</span> : Optional[pydantic.types.PositiveInt]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.callbacks"><code class="name">var <span class="ident">callbacks</span> : Optional[List[tensorflow.python.keras.callbacks.Callback]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.custom_filters"><code class="name">var <span class="ident">custom_filters</span> : List[Callable]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.custom_mappers"><code class="name">var <span class="ident">custom_mappers</span> : List[Callable]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.epochs"><code class="name">var <span class="ident">epochs</span> : pydantic.types.PositiveInt</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.loss"><code class="name">var <span class="ident">loss</span> : tensorflow.python.keras.losses.Loss</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.metrics"><code class="name">var <span class="ident">metrics</span> : Optional[List[str]]</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.optimizer"><code class="name">var <span class="ident">optimizer</span> : tensorflow.python.keras.optimizer_v2.optimizer_v2.OptimizerV2</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.seed"><code class="name">var <span class="ident">seed</span> : pydantic.types.PositiveInt</code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="fontai.config.prediction.TrainingConfig.steps_per_epoch"><code class="name">var <span class="ident">steps_per_epoch</span> : pydantic.types.PositiveInt</code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Static methods</h3>
<dl>
<dt id="fontai.config.prediction.TrainingConfig.from_yaml"><code class="name flex">
<span>def <span class="ident">from_yaml</span></span>(<span>yaml)</span>
</code></dt>
<dd>
<div class="desc"><p>Instantiate from a yml.YAML object</p>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>yaml</code></strong> :&ensp;<code>yml.YAML</code></dt>
<dd>Input YAML object following the schema given by ConfigHandler.training_config_schema</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code><a title="fontai.config.prediction.TrainingConfig" href="#fontai.config.prediction.TrainingConfig">TrainingConfig</a></code></dt>
<dd>Initialised object</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">@classmethod
def from_yaml(cls, yaml):
  &#34;&#34;&#34;Instantiate from a yml.YAML object
  
  Args:
      yaml (yml.YAML): Input YAML object following the schema given by ConfigHandler.training_config_schema
  
  Returns:
      TrainingConfig: Initialised object
  &#34;&#34;&#34;
  schema_handler = SimpleClassInstantiator()
  callback_factory = CallbackFactory()
  args = yaml.data

  # the following objects are not primitive types and need to be instantiated from YAML definitions
  args[&#34;optimizer&#34;] = schema_handler.get_instance(yaml=yaml.get(&#34;optimizer&#34;), scope=keras.optimizers)
  args[&#34;loss&#34;] = schema_handler.get_instance(yaml=yaml.get(&#34;loss&#34;), scope=keras.losses)
  
  if  yaml.get(&#34;custom_filters&#34;).data != []:
    args[&#34;custom_filters&#34;] = [getattr(custom_filters, subYAML.get(&#34;name&#34;).text)(**subYAML.get(&#34;kwargs&#34;).data) for subYAML in yaml.get(&#34;custom_filters&#34;)]
  else:
    args[&#34;custom_filters&#34;] = []


  if  yaml.get(&#34;custom_mappers&#34;).data != []:
    args[&#34;custom_mappers&#34;] = [getattr(custom_mappers, subYAML.get(&#34;name&#34;).text)(**subYAML.get(&#34;kwargs&#34;).data) for subYAML in yaml.get(&#34;custom_mappers&#34;)]
  else:
    args[&#34;custom_mappers&#34;] = []


  if  yaml.get(&#34;callbacks&#34;) is not None:
    args[&#34;callbacks&#34;] = [CallbackFactory.create(yaml) for yaml in yaml.get(&#34;callbacks&#34;)]
  else:
    args[&#34;callbacks&#34;] = None

  return TrainingConfig(**args)</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="fontai.config" href="index.html">fontai.config</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="fontai.config.prediction.CallbackFactory" href="#fontai.config.prediction.CallbackFactory">CallbackFactory</a></code></h4>
<ul class="">
<li><code><a title="fontai.config.prediction.CallbackFactory.create" href="#fontai.config.prediction.CallbackFactory.create">create</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fontai.config.prediction.Config" href="#fontai.config.prediction.Config">Config</a></code></h4>
<ul class="">
<li><code><a title="fontai.config.prediction.Config.Config" href="#fontai.config.prediction.Config.Config">Config</a></code></li>
<li><code><a title="fontai.config.prediction.Config.allowed_charsets" href="#fontai.config.prediction.Config.allowed_charsets">allowed_charsets</a></code></li>
<li><code><a title="fontai.config.prediction.Config.charset" href="#fontai.config.prediction.Config.charset">charset</a></code></li>
<li><code><a title="fontai.config.prediction.Config.input_record_class" href="#fontai.config.prediction.Config.input_record_class">input_record_class</a></code></li>
<li><code><a title="fontai.config.prediction.Config.model" href="#fontai.config.prediction.Config.model">model</a></code></li>
<li><code><a title="fontai.config.prediction.Config.model_path" href="#fontai.config.prediction.Config.model_path">model_path</a></code></li>
<li><code><a title="fontai.config.prediction.Config.training_config" href="#fontai.config.prediction.Config.training_config">training_config</a></code></li>
<li><code><a title="fontai.config.prediction.Config.validate_input_record_class" href="#fontai.config.prediction.Config.validate_input_record_class">validate_input_record_class</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fontai.config.prediction.ConfigHandler" href="#fontai.config.prediction.ConfigHandler">ConfigHandler</a></code></h4>
<ul class="">
<li><code><a title="fontai.config.prediction.ConfigHandler.get_config_schema" href="#fontai.config.prediction.ConfigHandler.get_config_schema">get_config_schema</a></code></li>
<li><code><a title="fontai.config.prediction.ConfigHandler.instantiate_config" href="#fontai.config.prediction.ConfigHandler.instantiate_config">instantiate_config</a></code></li>
<li><code><a title="fontai.config.prediction.ConfigHandler.other_setup" href="#fontai.config.prediction.ConfigHandler.other_setup">other_setup</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fontai.config.prediction.ModelFactory" href="#fontai.config.prediction.ModelFactory">ModelFactory</a></code></h4>
<ul class="">
<li><code><a title="fontai.config.prediction.ModelFactory.from_keras_sequential" href="#fontai.config.prediction.ModelFactory.from_keras_sequential">from_keras_sequential</a></code></li>
<li><code><a title="fontai.config.prediction.ModelFactory.from_multi_sequential" href="#fontai.config.prediction.ModelFactory.from_multi_sequential">from_multi_sequential</a></code></li>
<li><code><a title="fontai.config.prediction.ModelFactory.from_path" href="#fontai.config.prediction.ModelFactory.from_path">from_path</a></code></li>
<li><code><a title="fontai.config.prediction.ModelFactory.from_yaml" href="#fontai.config.prediction.ModelFactory.from_yaml">from_yaml</a></code></li>
</ul>
</li>
<li>
<h4><code><a title="fontai.config.prediction.TrainingConfig" href="#fontai.config.prediction.TrainingConfig">TrainingConfig</a></code></h4>
<ul class="two-column">
<li><code><a title="fontai.config.prediction.TrainingConfig.Config" href="#fontai.config.prediction.TrainingConfig.Config">Config</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.batch_size" href="#fontai.config.prediction.TrainingConfig.batch_size">batch_size</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.callbacks" href="#fontai.config.prediction.TrainingConfig.callbacks">callbacks</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.custom_filters" href="#fontai.config.prediction.TrainingConfig.custom_filters">custom_filters</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.custom_mappers" href="#fontai.config.prediction.TrainingConfig.custom_mappers">custom_mappers</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.epochs" href="#fontai.config.prediction.TrainingConfig.epochs">epochs</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.from_yaml" href="#fontai.config.prediction.TrainingConfig.from_yaml">from_yaml</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.loss" href="#fontai.config.prediction.TrainingConfig.loss">loss</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.metrics" href="#fontai.config.prediction.TrainingConfig.metrics">metrics</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.optimizer" href="#fontai.config.prediction.TrainingConfig.optimizer">optimizer</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.seed" href="#fontai.config.prediction.TrainingConfig.seed">seed</a></code></li>
<li><code><a title="fontai.config.prediction.TrainingConfig.steps_per_epoch" href="#fontai.config.prediction.TrainingConfig.steps_per_epoch">steps_per_epoch</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc" title="pdoc: Python API documentation generator"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>